{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irr3kxwyShZk"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform\n",
        "!pip install langchain\n",
        "!pip install chromadb\n",
        "!pip install pytube\n",
        "!pip install youtube-transcript-api\n",
        "!pip install gradio\n",
        "from google.cloud import aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "rlMFq7JaSyo4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "PROJECT_ID = \"ai-projects-404911\"\n",
        "vertexai.init(project=PROJECT_ID)"
      ],
      "metadata": {
        "id": "WH3vMDzsUbGm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import YoutubeLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import VertexAI"
      ],
      "metadata": {
        "id": "SpY5QNDUU20T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = VertexAI(\n",
        "model_name=\"text-bison@001\",\n",
        "max_output_tokens=256,\n",
        "temperature=0.1, #ouput\n",
        "top_p=0.8,\n",
        "top_k=40,\n",
        "verbose=True,\n",
        ")\n",
        "\n",
        "# Top p - Set the probability (minimum) that a token must qualify in order to be picked as a next possible token\n",
        "# Top k - Number of tokens to consider out of which you want to pick the next possible token from."
      ],
      "metadata": {
        "id": "Iz6rjWenU8fk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "\n",
        "# Embedding\n",
        "EMBEDDING_QPM = 100  #thresholds\n",
        "EMBEDDING_NUM_BATCH =5 #at diff batches\n",
        "embeddings = VertexAIEmbeddings(\n",
        "    requests_per_minute=EMBEDDING_QPM,\n",
        "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
        ")\n",
        "\n",
        "# Batch predictions are a way to efficiently send large numbers of  text prompts requests.\n",
        "# Different from online prediction, where you are limited to one input request at a time,\n",
        "# you can send a large number of LLM requests in a single batch request"
      ],
      "metadata": {
        "id": "u9n2-L0YVEQj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=A8jyW_6hCGU&t=161s\", add_video_info=True)\n",
        "result = loader.load()"
      ],
      "metadata": {
        "id": "zY1BT1WXWPeO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(result)\n",
        "print(f\"# of documents = {len(docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rayxa3pwWbX4",
        "outputId": "86c7b1a5-2ec0-4348-cc81-df4f087c67de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of documents = 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert text to vector to Cromadb\n",
        "db = Chroma.from_documents(docs, embeddings)\n",
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "eL3foKJvWhDx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a retriever chain to answer the question. This is where we associate the Vertex AI Text Bison model LLM and the retriever that retrieves the embeddings from Chroma DB.\n",
        "qa = RetrievalQA.from_chain_type( llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
      ],
      "metadata": {
        "id": "zlLrFWWgXFF7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sm_ask(question, print_results=True):\n",
        "  video_subset = qa({\"query\": question})\n",
        "  context = video_subset\n",
        "  prompt = f\"\"\"\n",
        "  Answer the following question in a detailed manner, using information from the text below. If the answer is not in the text,say I dont know and do not generate your own response.\n",
        "\n",
        "  Question:\n",
        "  {question}\n",
        "  Text:\n",
        "  {context}\n",
        "\n",
        "  Question:\n",
        "  {question}\n",
        "\n",
        "  Answer:\n",
        "  \"\"\"\n",
        "  parameters = {\n",
        "  \"temperature\": 0.1,\n",
        "  \"max_output_tokens\": 256,\n",
        "  \"top_p\": 0.8,\n",
        "  \"top_k\": 40\n",
        "  }\n",
        "  response = llm.predict(prompt, **parameters)\n",
        "  return {\n",
        "  \"answer\": response\n",
        "\n",
        "  }\n",
        "\n",
        "  # Define your prompt to ask questions and get answers from the indexed content."
      ],
      "metadata": {
        "id": "ulT_0ZwsXKPd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Integrate the LLM application with Gradio for a visual front end interaction.\n",
        "import gradio as gr\n",
        "def get_response(input_text):\n",
        "  response = sm_ask(input_text)\n",
        "  return response\n",
        "\n",
        "grapp = gr.Interface(fn=get_response, inputs=\"text\", outputs=\"text\")\n",
        "grapp.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "LiPMJMi0XpVK",
        "outputId": "951017dc-b085-45cb-b650-b9a6ac923b1f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://74f17e56119a6668f8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://74f17e56119a6668f8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dp382T4fX0bW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}